---
layout: archive
title: "Research Experience"
permalink: /research/
author_profile: true
---

## [Systems Imaging & Bioinformatics Lab](https://sibl.lab.medicine.umich.edu/){:style="text-decoration: none"}{:target="_blank"} @ UM 
---

<span style="font-size:1.05em;">**Background**</span>  
<span style="font-size:0.9em;"> 
Characterizing the tumor immune microenvironment is essential for understanding the mechanisms of cancer progression and immune response. The development of spatially resolved technologies has revolutionized our ability to study the TME, necessitating the development of methods that can quantify and discover biomarkers of disease.
  
<span style="font-size:1.05em;">**My work**</span>  
<span style="font-size:0.9em;">
I am developing deep learning algorithms and a workflow for instance segmentation of immune cells and tissue subtypes in histopathology slides, with only sparse labels available. Specifically, we are collaborating with pathologists from Johns Hopkins Hospital to analyze precursor lesions of ovarian cancer.  

## [Wirtz/Wu Lab](https://wirtzlab.johnshopkins.edu/){:style="text-decoration: none"}{:target="_blank"} @ JHU 
---

<span style="font-size:1.05em;">**Background**</span>  
<span style="font-size:0.9em;"> 
Assessing histopathology slides is critical for diagnosing and researching cancer, but is challenging and time consuming for expert pathologists. While integrating deep learning in the field of pathology is promising, there are many challenges in data variability, annotation availability, and generalizability that stand in the way of adoption to the clinic.  
  
<span style="font-size:1.05em;">**My work**</span>  
<span style="font-size:0.9em;">
I am developing deep learning algorithms and a workflow for instance segmentation of immune cells and tissue subtypes in histopathology slides, with only sparse labels available. Specifically, we are collaborating with pathologists from Johns Hopkins Hospital to analyze precursor lesions of ovarian cancer.  


## [Fertig Lab](https://fertiglab.com/){:style="text-decoration: none"}{:target="_blank"} & [Stein-O'Brien Lab](http://www.steinobrienlab.org/){:style="text-decoration: none"}{:target="_blank"} @ JHU 
---

<span style="font-size:1.05em;">**Background**</span>  
<span style="font-size:0.9em;"> 
Non-negative matrix factorization is ideal for uncovering hidden patterns in single-cell data, but its implementation and interpretation can be challenging. This highlights the need for frameworks that are user-friendly, integrable, and efficient for such analyses.

<span style="font-size:1.05em;">**My work**</span>  
<span style="font-size:0.9em;">
I created [PyCoGAPS](https://www.nature.com/articles/s41596-023-00892-x){:style="text-decoration: none"}{:target="_blank"}, a Python implementation of [CoGAPS](https://bmcbioinformatics.biomedcentral.com/articles/10.1186/s12859-020-03796-9){:style="text-decoration: none"}{:target="_blank"} which is a Bayesian NMF algorithm for gene set analysis. PyCoGAPS enahnces runtime for large datasets, on the scale of tens of hours compared to CoGAPS, and additional workflows I developed with Docker and GenePattern facilitate user-friendly interpretation and implementation of NMF for single-cell analyses. 

## [Precision Care Medicine](https://sarmalab.icm.jhu.edu/courses/precision-care-medicine/){:style="text-decoration: none"}{:target="_blank"} @ JHU 
---
 
<span style="font-size:1.05em;">**Background**</span>  
<span style="font-size:0.9em;"> 
Static ocular torsion assessment is an important clinical tool for identifying abnormalities in the vestibular-ocular-motor pathway, but current methods are time-intensive with steep learning curves.  
  
<span style="font-size:1.05em;">**My work**</span>  
<span style="font-size:0.9em;">
I worked with a team of students to curate a synthetic, realistic dataset for static ocular torsion, and developed a classification model for assessing torsion from fundus images. We worked in collaboration with Johns Hopkins Hospital neurologists and researchers.

## [Malone Center for Engineering in Healthcare](https://malonecenter.jhu.edu/){:style="text-decoration: none"}{:target="_blank"} @ JHU 
---

<span style="font-size:1.05em;">**Background**</span>  
<span style="font-size:0.9em;"> 
Computer-assisted robotic surgeries have the potential to improve critical and common procedures, such as cataract surgeries, requiring fine precision and accuracy. A major component to its implementation involves the application of computer vision in order to detect regions of interest.  
  
<span style="font-size:1.05em;">**My work**</span>  
<span style="font-size:0.9em;">
I created a user-friendly script for annotating pupil segmentations across video frames of cataract surgical procedures. Following dataset curation, I implemented traditional computer vision methods and explored deep learning for segmentation of regions of interest.  
